# Word Sense Disambiguation Research Project 2020

This summer (May - September), I had the opportunity of working with Professor Kemal Oflazer on a new approach to the WSD problem. We attempted to use Google's BERT base and large models to fine-tune for word sense labels. Through this, we took an approach of fine-tuning the word embeddings themselves. This allowed us to closely match CLS tokens to target word (desired sense) embeddings. By doing this, we did not have to fine-tune a separate model for each stem word. It allows us to fine-tune BERT on all senses all at the same time.
<br>
<br>
Skills Learned:
*
